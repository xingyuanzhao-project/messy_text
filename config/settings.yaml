model:
  name: "hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4"
  api_base: "http://localhost:8000/v1"
  api_key: "dummy"

paths:
  input: "df_text.csv"
  output:
    file: "df_text_clas_multi_server.csv"
    extend: False
  eval_output: "df_text_multi_eval.csv"
  taxonomy: "config/taxonomy.json"

async:
  enabled: False
  max_retries: 5
  max_concurrent_rows: 50

processing:
  temperature: 0.0
  max_tokens_summary: 1024
  max_tokens_classification: 256
  start_index: 0
  early_break: 3
  inner_loop_break: 3

evaluation:
  rows_eval_break: 3
  benchmarks:
    enable_geval_summarization: True
    enable_geval_hallucination: True
    enable_summac_zs: True
    enable_summac_conv: True
    enable_default_metrics: True

    summac_settings:
      device: "cuda"
      granularity: "sentence"
      model_name: "vitc"


display:
  use_progress_bar: True

logging:
  log_resources: false
  log_prompts: false
  log_response: false
  log_progress: True
  file: "processing.log"
